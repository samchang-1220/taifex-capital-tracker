import requests
import pandas as pd
import io
import os
from datetime import datetime, timedelta, timezone

# --- ç’°å¢ƒè®Šæ•¸ ---
TG_TOKEN = os.getenv('TG_TOKEN')
TG_CHAT_ID = os.getenv('TG_CHAT_ID')

# å•†å“æ¸…å–®é…ç½®ï¼š(ä»£è™Ÿ, æ³•äººæª”åé—œéµå­—, é¡¯ç¤ºåç¨±, è³‡æ–™åº«æª”å)
CONFIG = {
    'TXF': ('TX', 'è‡ºè‚¡æœŸè²¨', 'å°æŒ‡æœŸ', 'history_data_txf.csv'),
    'UNF': ('UNF', 'ç¾åœ‹é‚£æ–¯é”å…‹100æœŸè²¨', 'é‚£æ–¯é”å…‹', 'history_data_unf.csv')
}

def get_taiwan_time():
    return datetime.now(timezone(timedelta(hours=8)))

def send_telegram(message):
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    payload = {'chat_id': TG_CHAT_ID, 'text': message, 'parse_mode': 'Markdown'}
    requests.post(url, data=payload)

def download_file(url, payload, headers):
    session = requests.Session()
    session.get("https://www.taifex.com.tw/cht/3/dlLargeTraderFutView", headers=headers)
    resp = session.post(url, data=payload, headers=headers, timeout=20)
    if b"DOCTYPE" in resp.content[:100] or len(resp.content) < 500:
        return None
    return resp.content

def update_db(db_file, date_str, data):
    if os.path.exists(db_file):
        df_history = pd.read_csv(db_file)
    else:
        df_history = pd.DataFrame(columns=['æ—¥æœŸ', 'ç‰¹å®šäº”å¤§è²·', 'ç‰¹å®šäº”å¤§è³£', 'ç‰¹å®šäº”å¤§æ·¨', 'å¤–è³‡æ·¨é¡', 'æŠ•ä¿¡æ·¨é¡', 'å¤§å¤–è³‡', 'å°å¤–è³‡'])
    
    df_history['æ—¥æœŸ'] = df_history['æ—¥æœŸ'].astype(str)
    df_history = df_history[df_history['æ—¥æœŸ'] != date_str] # è¦†è“‹èˆŠæ•¸æ“š
    new_df = pd.DataFrame([data])
    df_history = pd.concat([df_history, new_df], ignore_index=True).sort_values('æ—¥æœŸ')
    df_history.to_csv(db_file, index=False, encoding='utf-8-sig')

def process_product(symbol, large_df, date_str):
    conf = CONFIG[symbol]
    large_code, inst_name, display_name, db_file = conf
    
    # 1. æŠ“å–è©²å•†å“çš„ä¸‰å¤§æ³•äººè³‡æ–™
    inst_url = "https://www.taifex.com.tw/cht/3/dlFutContractsDateDown"
    payload = {'queryStartDate': date_str, 'queryEndDate': date_str, 'commodityId': symbol}
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    inst_content = download_file(inst_url, payload, headers)
    if inst_content is None:
        return f"âš ï¸ {display_name} æ³•äººè³‡æ–™å°šæœªæ›´æ–°ã€‚"

    # 2. è§£ææ•¸æ“š
    try:
        # å¤§é¡äº¤æ˜“äººæ•¸æ“šæå–
        mask = (large_df.iloc[:, 1].astype(str).str.strip() == large_code) & \
               (large_df.iloc[:, 3].astype(str).str.strip().str.contains("999999")) & \
               (large_df.iloc[:, 4].astype(str).str.strip() == "1")
        l_row = large_df[mask].iloc[0]
        top5_buy = int(float(l_row['å‰äº”å¤§äº¤æ˜“äººè²·æ–¹']))
        top5_sell = int(float(l_row['å‰äº”å¤§äº¤æ˜“äººè³£æ–¹']))
        top5_spec_net = top5_buy - top5_sell

        # ä¸‰å¤§æ³•äººæ•¸æ“šæå–
        df_inst = pd.read_csv(io.StringIO(inst_content.decode('cp950', errors='ignore')), skipinitialspace=True)
        df_inst.columns = [c.strip() for c in df_inst.columns]
        trust_net = int(df_inst[df_inst['èº«ä»½åˆ¥'].str.contains("æŠ•ä¿¡")]['å¤šç©ºæœªå¹³å€‰å£æ•¸æ·¨é¡'].values[0])
        foreign_net = int(df_inst[df_inst['èº«ä»½åˆ¥'].str.contains("å¤–è³‡")]['å¤šç©ºæœªå¹³å€‰å£æ•¸æ·¨é¡'].values[0])

        # å…¬å¼è¨ˆç®—
        big_f = top5_spec_net - trust_net
        small_f = foreign_net - big_f

        # å„²å­˜åˆ°è³‡æ–™åº«
        db_data = {'æ—¥æœŸ': date_str, 'ç‰¹å®šäº”å¤§è²·': top5_buy, 'ç‰¹å®šäº”å¤§è³£': top5_sell, 
                   'ç‰¹å®šäº”å¤§æ·¨': top5_spec_net, 'å¤–è³‡æ·¨é¡': foreign_net, 'æŠ•ä¿¡æ·¨é¡': trust_net, 
                   'å¤§å¤–è³‡': big_f, 'å°å¤–è³‡': small_f}
        update_db(db_file, date_str, db_data)

        # æ ¼å¼åŒ–è¨Šæ¯
        msg = (
            f"ğŸ† *{date_str} {display_name}å°å¤–è³‡å ±å‘Š*\n"
            f"```\n"
            f"ç‰¹å®šäº”å¤§è²·æ–¹ï¼š {top5_buy:>10,}\n"
            f"ç‰¹å®šäº”å¤§è³£æ–¹ï¼š {top5_sell:>10,}\n"
            f"ç‰¹å®šäº”å¤§æ·¨é¡ï¼š {top5_spec_net:>10,}\n"
            f"-----------------------------\n"
            f"å¤–è³‡ç¸½æ·¨é¡ï¼š   {foreign_net:>10,}\n"
            f"æŠ•ä¿¡ç¸½æ·¨é¡ï¼š   {trust_net:>10,}\n"
            f"-----------------------------\n"
            f"ğŸ”¥ å¤§å¤–è³‡ (Big F): {big_f:>10,}\n"
            f"ğŸŒŸ å°å¤–è³‡ (Small F): {small_f:>10,}\n"
            f"```\n"
            f"ğŸ“‚ å°å¤–è³‡ç•™å€‰å°éš”æ—¥å°è‚¡å¤šç©ºæœ‰é æ¸¬åŠ›ã€‚"
        )
        return msg
    except Exception as e:
        return f"âŒ {display_name} è§£æå¤±æ•—: {str(e)}"

def main():
    date_str = get_taiwan_time().strftime("%Y/%m/%d")
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    # ä¸‹è¼‰å¤§é¡äº¤æ˜“äººç¸½è¡¨
    large_url = "https://www.taifex.com.tw/cht/3/dlLargeTraderFutDown"
    large_payload = {'queryStartDate': date_str, 'queryEndDate': date_str}
    large_content = download_file(large_url, large_payload, headers)

    if large_content is None:
        send_telegram(f"âš ï¸ {date_str} ç„¡è³‡æ–™ï¼Œå¯èƒ½ç‚ºåœ‹å®šå‡æ—¥æˆ–ç¨‹å¼å£æ‰")
        return

    df_large = pd.read_csv(io.StringIO(large_content.decode('cp950', errors='ignore')), skipinitialspace=True)
    df_large.columns = [c.strip() for c in df_large.columns]

    # åˆ†åˆ¥è™•ç†å°æŒ‡èˆ‡é‚£æŒ‡
    for symbol in CONFIG.keys():
        report = process_product(symbol, df_large, date_str)
        send_telegram(report)

if __name__ == "__main__":
    main()
