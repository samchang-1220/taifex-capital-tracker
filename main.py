import requests
import pandas as pd
from datetime import datetime, timedelta
import os
import io

# --- è¨­å®šå€ ---
TG_TOKEN = os.getenv('TG_TOKEN')
TG_CHAT_ID = os.getenv('TG_CHAT_ID')
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}

def send_tg_msg(message):
    if not TG_TOKEN or not TG_CHAT_ID:
        print("âŒ æœªè¨­å®š TG Token æˆ– Chat ID")
        return
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    payload = {"chat_id": TG_CHAT_ID, "text": message, "parse_mode": "Markdown"}
    try:
        r = requests.post(url, json=payload)
        print(f"TG ç™¼é€ç‹€æ…‹: {r.status_code}, å›æ‡‰: {r.text}")
    except Exception as e:
        print(f"TG ç™¼é€ç•°å¸¸: {e}")

def get_taifex_table(url, date_str, match_text):
    """é€šç”¨æŠ“å–æœŸäº¤æ‰€è¡¨æ ¼å‡½æ•¸"""
    try:
        resp = requests.post(url, data={'queryDate': date_str}, headers=HEADERS, timeout=15)
        if "æŸ¥ç„¡è³‡æ–™" in resp.text or not resp.text.strip():
            return None
        
        # æŠ“å–æ‰€æœ‰è¡¨æ ¼
        dfs = pd.read_html(io.StringIO(resp.text))
        for df in dfs:
            # åªè¦è¡¨æ ¼å…§å®¹åŒ…å«é—œéµå­—ï¼Œå°±æ˜¯æˆ‘å€‘è¦çš„
            if df.astype(str).apply(lambda x: x.str.contains(match_text)).any().any():
                return df
    except Exception as e:
        print(f"æŠ“å–å¤±æ•— ({match_text}): {e}")
    return None

def get_futures_data():
    check_date = datetime.now()
    found_data = False
    max_tries = 10 
    
    while not found_data and max_tries > 0:
        date_str = check_date.strftime("%Y/%m/%d")
        print(f"ğŸ” å˜—è©¦æŠ“å–æ—¥æœŸ: {date_str}...")
        
        # 1. æŠ“å–ä¸‰å¤§æ³•äºº
        df_inst = get_taifex_table("https://www.taifex.com.tw/cht/3/futContractsDate", date_str, "è‡ºè‚¡æœŸè²¨")
        # 2. æŠ“å–å¤§é¡äº¤æ˜“äºº
        df_large = get_taifex_table("https://www.taifex.com.tw/cht/3/largeTradersFutQry", date_str, "è‡ºè‚¡æœŸè²¨")

        if df_inst is not None and df_large is not None:
            found_data = True
            print(f"âœ… æˆåŠŸæ‰¾åˆ° {date_str} çš„æ•¸æ“š")
            break
        
        check_date -= timedelta(days=1)
        max_tries -= 1

    if not found_data:
        return None, None

    results = []
    # æ¨™çš„å°æ‡‰ (å°æŒ‡æœŸ, é‚£æŒ‡æœŸ)
    targets = [
        {"name": "å°æŒ‡æœŸ", "inst_code": "è‡ºè‚¡æœŸè²¨", "large_code": "è‡ºè‚¡æœŸè²¨"},
        {"name": "é‚£æŒ‡æœŸ", "inst_code": "ç¾åœ‹é‚£æ–¯é”å…‹100æœŸè²¨", "large_code": "ç¾åœ‹é‚£æ–¯é”å…‹100"}
    ]

    for t in targets:
        try:
            # --- ä¸‰å¤§æ³•äººæ•¸æ“š ---
            # æ‰¾åˆ°æ¨™çš„æ‰€åœ¨åˆ—
            inst_rows = df_inst[df_inst.iloc[:, 1].str.contains(t['inst_code'], na=False)]
            # å¤–è³‡é€šå¸¸æ˜¯è©²æ¨™çš„çš„ç¬¬1åˆ—ï¼ŒæŠ•ä¿¡ç¬¬2åˆ—ã€‚æœªå¹³å€‰æ·¨é¡åœ¨ç¬¬13æ¬„
            f_net = int(inst_rows.iloc[0, 13])
            i_net = int(inst_rows.iloc[1, 13])

            # --- å¤§é¡äº¤æ˜“äººæ•¸æ“š ---
            large_rows = df_large[df_large.iloc[:, 1].str.contains(t['large_code'], na=False)]
            # æŠ“å–ã€Œæ‰€æœ‰æœˆä»½ã€ä¸”ã€Œå‰äº”å¤§ã€ä¹‹ã€Œç‰¹å®šæ³•äººã€çš„å¤šç©ºé ­éƒ¨ä½ (æ¬„ä½ 5, 6)
            top5_buy = int(large_rows.iloc[0, 5])
            top5_sell = int(large_rows.iloc[0, 6])
            top5_net = top5_buy - top5_sell

            # --- å…¬å¼è¨ˆç®— ---
            big_f = top5_net - i_net
            small_f = f_net - big_f
            
            results.append({
                "æ¨™çš„": t['name'],
                "å¤–è³‡": f_net,
                "å¤§å¤–è³‡": big_f,
                "å°å¤–è³‡": small_f,
                "é æ¸¬": "ğŸŸ¢ åå¤š" if small_f > 0 else "ğŸ”´ åç©º"
            })
        except Exception as e:
            print(f"âš ï¸ è§£æ {t['name']} å¤±æ•—: {e}")

    return date_str, results

def main():
    date_str, data = get_futures_data()
    
    if not data:
        send_tg_msg("âŒ ç³»çµ±éŒ¯èª¤ï¼šå›æº¯ 10 å¤©ä»ç„¡æ³•è§£ææœŸäº¤æ‰€æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²é æ ¼å¼ã€‚")
        return

    # å­˜æª” CSV
    file_path = 'data/futures_history.csv'
    os.makedirs('data', exist_ok=True)
    df_new = pd.DataFrame(data)
    df_new['Date'] = date_str
    
    if os.path.exists(file_path):
        df_old = pd.read_csv(file_path)
        df_final = pd.concat([df_old, df_new]).drop_duplicates(subset=['Date', 'æ¨™çš„'], keep='last')
    else:
        df_final = df_new
    df_final.to_csv(file_path, index=False, encoding='utf-8-sig')

    # TG æ¨é€
    msg = f"ğŸ“Š *æ¯æ—¥å°å¤–è³‡ç±Œç¢¼å ±å‘Š*\nğŸ“… è³‡æ–™æ—¥æœŸï¼š{date_str}\n"
    msg += "---" + "\n"
    for item in data:
        msg += f"ã€{item['æ¨™çš„']}ã€‘\n"
        msg += f"â–«ï¸ å¤–è³‡: {item['å¤–è³‡']:,}\n"
        msg += f"â–«ï¸ å¤§å¤–è³‡: {item['å¤§å¤–è³‡']:,}\n"
        msg += f"â–«ï¸ *å°å¤–è³‡: {item['å°å¤–è³‡']:,}*\n"
        msg += f"ğŸ’¡ é æ¸¬: {item['é æ¸¬']}\n\n"
    
    send_tg_msg(msg)

if __name__ == "__main__":
    main()
