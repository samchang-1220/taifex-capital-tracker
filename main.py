import requests
import pandas as pd
from datetime import datetime
import os
import json

# --- è¨­å®šå€ ---
TG_TOKEN = os.getenv('TG_TOKEN')
TG_CHAT_ID = os.getenv('TG_CHAT_ID')

def send_tg_msg(message):
    if not TG_TOKEN or not TG_CHAT_ID: return
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    requests.post(url, json={"chat_id": TG_CHAT_ID, "text": message, "parse_mode": "Markdown"})

def fetch_api_safely(url):
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        r = requests.get(url, headers=headers, timeout=15)
        if r.status_code != 200:
            print(f"âŒ API å¤±æ•—ç¢¼: {r.status_code} URL: {url}")
            return None
        
        # å˜—è©¦è§£æ JSON
        return r.json()
    except json.JSONDecodeError:
        print(f"âŒ è§£æå¤±æ•—ï¼æ”¶åˆ°çš„å…§å®¹ä¸æ˜¯ JSONã€‚å…§å®¹é–‹é ­ç‚º: {r.text[:100]}")
        return None
    except Exception as e:
        print(f"âŒ é€£ç·šç•°å¸¸: {e}")
        return None

def main():
    print("ğŸš€ é–‹å§‹åŸ·è¡Œ API æŠ“å–ä»»å‹™...")
    
    # 1. æŠ“å–ä¸‰å¤§æ³•äºº API
    inst_data = fetch_api_safely("https://openapi.taifex.com.tw/v1/FuturesThreeInstitutionalExchanges")
    # 2. æŠ“å–å¤§é¡äº¤æ˜“äºº API
    large_data = fetch_api_safely("https://openapi.taifex.com.tw/v1/DailyFuturesTradersRegion")

    if not inst_data or not large_data:
        send_tg_msg("âš ï¸ *ç³»çµ±è­¦å‘Š*ï¼šæœŸäº¤æ‰€ API å›å‚³æ ¼å¼éŒ¯èª¤æˆ–é­å°é–ã€‚è«‹æª¢æŸ¥ GitHub Actions Logã€‚")
        return

    # è½‰ç‚º DataFrame
    df_inst = pd.DataFrame(inst_data)
    df_large = pd.DataFrame(large_data)
    
    # å–å¾—æœ€æ–°æ—¥æœŸ
    latest_date = df_inst['Date'].max()
    results = []

    # æ¨™çš„å°æ‡‰
    targets = [
        {"name": "å°æŒ‡æœŸ", "t_code": "TX", "l_code": "TX"},
        {"name": "é‚£æŒ‡æœŸ", "t_code": "UNF", "l_code": "UNF"}
    ]

    for t in targets:
        try:
            # --- æ•¸æ“šéæ¿¾ ---
            # å¤–è³‡ = 003, æŠ•ä¿¡ = 001
            f_net = int(df_inst[(df_inst['SymbolId'] == t['t_code']) & (df_inst['InstitutionalEntityId'] == '003')]['OpenInterestNetCount'].values[0])
            i_net = int(df_inst[(df_inst['SymbolId'] == t['t_code']) & (df_inst['InstitutionalEntityId'] == '001')]['OpenInterestNetCount'].values[0])
            
            l_row = df_large[(df_large['SymbolId'] == t['l_code']) & (df_large['ContractMonthOrWeek'] == 'All')].iloc[0]
            top5_spec_net = int(l_row['Top5SpecificLongCount']) - int(l_row['Top5SpecificShortCount'])

            # --- å…¬å¼è¨ˆç®— ---
            big_f = top5_spec_net - i_net
            small_f = f_net - big_f
            
            results.append({
                "æ¨™çš„": t['name'],
                "å¤–è³‡": f_net,
                "å¤§å¤–è³‡": big_f,
                "å°å¤–è³‡": small_f,
                "é æ¸¬": "ğŸŸ¢ åå¤š" if small_f > 0 else "ğŸ”´ åç©º"
            })
        except Exception as e:
            print(f"âš ï¸ {t['name']} æ•¸æ“šè§£æå¤±æ•—: {e}")

    if results:
        # å­˜æª”è‡³ CSV
        file_path = 'data/futures_history.csv'
        os.makedirs('data', exist_ok=True)
        df_new = pd.DataFrame(results)
        df_new['Date'] = latest_date
        
        if os.path.exists(file_path):
            df_old = pd.read_csv(file_path)
            df_final = pd.concat([df_old, df_new]).drop_duplicates(subset=['Date', 'æ¨™çš„'], keep='last')
        else:
            df_final = df_new
        df_final.to_csv(file_path, index=False, encoding='utf-8-sig')

        # TG æ¨é€
        msg = f"ğŸš€ *å°å¤–è³‡ç±Œç¢¼é æ¸¬å ±å‘Š*\nğŸ“… è³‡æ–™æ—¥æœŸï¼š{latest_date}\n"
        msg += "---" + "\n"
        for item in results:
            msg += f"ã€{item['æ¨™çš„']}ã€‘\n"
            msg += f"â–«ï¸ å¤§å¤–è³‡: {item['å¤§å¤–è³‡']:,}\n"
            msg += f"â–«ï¸ *å°å¤–è³‡: {item['å°å¤–è³‡']:,}*\n"
            msg += f"ğŸ’¡ é æ¸¬: {item['é æ¸¬']}\n\n"
        send_tg_msg(msg)
        print("âœ… ä»»å‹™åœ“æ»¿å®Œæˆï¼")

if __name__ == "__main__":
    main()
